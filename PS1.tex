\documentclass[10pt]{article}
\usepackage[english]{babel}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{tabularx}
\usepackage{array}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{geometry}
\usepackage{cancel}
\usepackage{enumitem}
\geometry{hmargin=3.5cm,vmargin=3.5cm}

%\sectionfont{\fontsize{12}{15}\selectfont}

\title{Econometrics III - Problem Set 1}
\author{Attila Gyetvai \\
Jackson Bunting \\
Leonardo S S Chaves \\
Peter Horvarth \\
Department of Economics - Duke University}
\date{\today}

\begin{document}

\maketitle

%--------------------------------------------------------------------------%
\section*{Question 1}

\paragraph{}


%--------------------------------------------------------------------------%
\section*{Question 3}

\paragraph{}Let $\{X_i\}_{i \in \mathbb{N}}$ be a sequence of random variables with mean $\mu$. Suppose that $Cov(X_t,X_s)=0 \forall t\neq s$ and $Var(X_t) \leq Kt^{1/2}$ for some constant $K>0$. Show that $\bar{X_t} \overset{\mathbb{P}}{\rightarrow} \mu$.\\

\textbf{Solution:} Consider any $\epsilon>0$. Using Markov inequality we get
\begin{align*}
P(|\bar{X_t} - \mu| > \epsilon) &\leq \frac{\mathbb{E}( |\bar{X_t} - \mu|^2)}{\epsilon^2} = \frac{V(\bar{X_t})}{\epsilon^2} \\
&\leq \frac{\sum_{t=1}^T V(X_t)}{T^2 \epsilon^2} = \frac{K \sum_{t=1}^T t^{1/2}}{T^2 \epsilon^2} \\
&\leq \frac{K T^{3/2}}{T^2 \epsilon^2} \overset{t \to \infty}{\longrightarrow} 0
\end{align*}

Then $\bar{X_t} - \mu \overset{\mathbb{P}}{\rightarrow} 0$ which is equivalent to what we wanted to show.


%--------------------------------------------------------------------------%
\section*{Question 5}

\paragraph{}Suppose that $\sup_{t \in \mathcal{T}} \mathbb{E}(|X_t|^{1+\delta}) < \infty$ for some $\delta >0$. Then $\{X_t : t \in \mathcal{T}\}$ is uniformly integrable. (Hint: Markov's inequality) \\

\textbf{Solution:} Notice that $\sup_{t \in \mathcal{T}} \mathbb{E}(|X_t|I_{[|X_t|>M]}) \leq \sup_{t \in \mathcal{T}} \mathbb{E}(|X_t|) \sup_{t \in \mathcal{T}}P(X_t >M)$.

From Markov inequality we have
\begin{align*}
P(|X_t|>M)&\leq \frac{\mathbb{E}(|X_t|^{1+\delta})}{M^{1+\delta}} \\
&< \frac{\eta}{M^2} \overset{M \to \infty}{\longrightarrow} 0
\end{align*}
Moreover, assuming $\sup_{t \in \mathcal{T}} \mathbb{E}(|X_t|^{1+\delta}) < \infty$ implies that $\sup_{t \in \mathcal{T}} \mathbb{E}(|X_t|)<\infty$.

All of it implies that $\lim_{M \to \infty} \sup_{t \in \mathcal{T}} \mathbb{E}(|X_t| I_{[X_t| > M]}) \leq 0$. Since $|X_t| I_{[X_t| > M]}\geq 0$, we get the uniform integrability of $\{X_t : t \in \mathcal{T}\}$.



%--------------------------------------------------------------------------%
\section*{Question 11}

\paragraph{}Interpret and prove that $e^{o_p(1)} -1 = o_p(1)$ and $(O_p(1))^{\sqrt{2}} = O_p(1)$. \\

\textbf{Solution:} If you pick a r.v. $X = o_p(1)$, then a continuous transformation will also be $o_p(1)$. The proof is a straightforward consequence of CMT.

For the second claim, the interpretation is that you preserve $O_p(1)$ property when you take a continuous function of this r.v.. To prove, let $X_n = O_p(1)$. By definition, $\exists M>0 ; \sup_{n \in \mathbb{N}} P(|X_n|>M)<\epsilon)$. Notice that $\{\omega \in \Omega : |X_n(\omega)|>M\} = \{\omega \in \Omega : |X_n(\omega)|^{\sqrt{2}}>M^{\sqrt{2}}\}$ because it is a monotonic transformation. Thus, $\exists \eta = M^{\sqrt{2}}>0 ; \sup_{n \in \mathbb{N}} P(|X_n^{\sqrt{2}}|>\eta)<\epsilon)$.



\end{document}
